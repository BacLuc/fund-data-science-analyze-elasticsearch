{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcb2a67b",
   "metadata": {},
   "source": [
    "# Fundamentals of Software Systems (FSS)\n",
    "**Software Evolution – Part 02 Assignment**\n",
    "\n",
    "## Submission Guidelines\n",
    "\n",
    "To correctly complete this assignment you must:\n",
    "* Carry out the assignment in a team of 2 to 4 students.\n",
    "* Carry out the assignment with your team only. You are allowed to discuss solutions with other teams, but each team should come up its own personal solution. A strict plagiarism policy is going to be applied to all the artifacts submitted for evaluation.\n",
    "* As your submission, upload the filled Jupyter Notebook (including outputs) together with the d3 visualization web pages (i.e. upload everything you downloaded including the filled Jupyter Notebook plus your `output.json`)\n",
    "* The files must be uploaded to OLAT as a single ZIP (`.zip`) file by Dec 12, 2022 @ 23:55.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a552ae3",
   "metadata": {},
   "source": [
    "## Group Members\n",
    "* Firstname, Lastname, Immatrikulation Number\n",
    "* Lucius, Bachmann, 11-060-274\n",
    "* Adnreas, Wiemeyer, 15-728-405"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46791aa",
   "metadata": {},
   "source": [
    "## Task Context\n",
    "\n",
    "In this assigment we will be analyzing the _elasticsearch_ project. All following tasks should be done with the subset of commits from tag `v1.0.0` to tag `v1.1.0`.\n",
    "\n",
    "Website: https://github.com/elastic/elasticsearch\n",
    "Repository: https://github.com/elastic/elasticsearch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4986ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Modification(Enum):\n",
    "    ADDED = \"Lines added\"\n",
    "    REMOVED = \"Lines removed\"\n",
    "    TOTAL = \"Lines added + lines removed\"\n",
    "    DIFF = \"Lines added - lines removed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# noinspection PyUnresolvedReferences\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "from os import path, mkdir\n",
    "\n",
    "# noinspection PyUnresolvedReferences\n",
    "import pandas as pd\n",
    "# noinspection PyUnresolvedReferences\n",
    "import plotly.express as px\n",
    "from pydriller import Repository, Git\n",
    "\n",
    "repo_remote_path = 'https://github.com/elastic/elasticsearch.git'\n",
    "repo_owner = 'elastic'\n",
    "repo_name = 'elasticsearch'\n",
    "repo_checkout_path = f'{repo_owner}/{repo_name}'\n",
    "\n",
    "if not path.exists(repo_owner):\n",
    "    mkdir(repo_owner)\n",
    "\n",
    "from_tag = 'v1.0.0'\n",
    "to_tag = 'v1.1.0'\n",
    "repo = Repository(repo_remote_path, clone_repo_to=repo_owner, from_tag=from_tag, to_tag=to_tag)\n",
    "# clone repo if necessary\n",
    "for commit in repo.traverse_commits():\n",
    "    break\n",
    "git = Git(repo_checkout_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "b1a29d1b",
   "metadata": {},
   "source": [
    "## Task 1: Author analysis\n",
    "\n",
    "In the following, please consider only `java` files.\n",
    "\n",
    "The first task is to get an overview of the author ownership of the _elasticsearch_ project. In particular, we want to understand who are the main authors in the system between the two considered tags, the authors distribution among files and the files distribution among authors. To this aim, perform the following:\n",
    "- create a dictionary (or a list of tuples) with the pairs author => number of modified files\n",
    "- create a dictionary (or a list of tuples) with the pairs file => number of authors who modified the file\n",
    "- visualize the distribution of authors among files: the visualization should have on the x axis the number of authors per file (from 1 to max), and on the y axis the number of files with the given number of authors (so for example the first bar represent the number of files with single author)\n",
    "- visualize the distribution of files among authors: the visualization should have on the x axis the number of files per author (from 1 to max), and on the y axis the number of authors who modified the given number of files (so for example the first bar represent the minor contributors, i.e., the number of authors who changed only 1 file)\n",
    "\n",
    "Comment the two distribution visualizations.\n",
    "\n",
    "\n",
    "\n",
    "Now, let's look at the following 3 packages in more detail:\n",
    "1. `src/main/java/org/elasticsearch/search`\n",
    "2. `src/main/java/org/elasticsearch/index`\n",
    "3. `src/main/java/org/elasticsearch/action`\n",
    "\n",
    "Create a function that, given the path of a package and a modification type (see class Modification above), returns a dictionary of authors => number, where the number counts the total lines added or removed or added+removed or added-removed (depending on the given Modification parameter), for the given package. To compute the value at the package level, you should aggregate the data per file.\n",
    "\n",
    "Using the function defined above, visualize the author contributions (lines added + lines removed). The visualization should have the author on the x axis, and the total lines on the y axis. Sort the visualization in decreasing amount of contributions, i.e., the main author should be the first.\n",
    "\n",
    "Compare the visualization for the 3 packages and comment."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Count the number of authors per file and the number of files per author."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a447987a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 12\u001B[0m\n\u001B[1;32m     10\u001B[0m author_identifier \u001B[38;5;241m=\u001B[39m commit\u001B[38;5;241m.\u001B[39mauthor\u001B[38;5;241m.\u001B[39mname\n\u001B[1;32m     11\u001B[0m authors_to_files\u001B[38;5;241m.\u001B[39msetdefault(author_identifier, \u001B[38;5;28mset\u001B[39m())\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m \u001B[43mcommit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodified_files\u001B[49m:\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m file\u001B[38;5;241m.\u001B[39mnew_path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m         files_to_authors\u001B[38;5;241m.\u001B[39msetdefault(file\u001B[38;5;241m.\u001B[39mnew_path, \u001B[38;5;28mset\u001B[39m())\n",
      "File \u001B[0;32m~/OneDrive - Universität Zürich UZH/Uni/Master 3/Fundamentals of Software Systems/Exercise/06/github/fund-data-science-analyze-elasticsearch/venv/lib/python3.8/site-packages/pydriller/domain/commit.py:667\u001B[0m, in \u001B[0;36mCommit.modified_files\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    658\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    659\u001B[0m \u001B[38;5;124;03mReturn a list of modified files. The list is empty if the commit is\u001B[39;00m\n\u001B[1;32m    660\u001B[0m \u001B[38;5;124;03ma merge commit. For more info on this, see\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    664\u001B[0m \u001B[38;5;124;03m:return: List[Modification] modifications\u001B[39;00m\n\u001B[1;32m    665\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    666\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_modified_files \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 667\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_modified_files \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_modified_files\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_modified_files \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    670\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_modified_files\n",
      "File \u001B[0;32m~/OneDrive - Universität Zürich UZH/Uni/Master 3/Fundamentals of Software Systems/Exercise/06/github/fund-data-science-analyze-elasticsearch/venv/lib/python3.8/site-packages/pydriller/domain/commit.py:682\u001B[0m, in \u001B[0;36mCommit._get_modified_files\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    678\u001B[0m     options[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    680\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparents) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    681\u001B[0m     \u001B[38;5;66;03m# the commit has a parent\u001B[39;00m\n\u001B[0;32m--> 682\u001B[0m     diff_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_c_object\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparents\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdiff\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    683\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_c_object\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_patch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptions\u001B[49m\n\u001B[1;32m    684\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    685\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparents) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    686\u001B[0m     \u001B[38;5;66;03m# if it's a merge commit, the modified files of the commit are the\u001B[39;00m\n\u001B[1;32m    687\u001B[0m     \u001B[38;5;66;03m# conflicts. This because if the file is not in conflict,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    694\u001B[0m     \u001B[38;5;66;03m# d = c_git.diff_tree(\"--cc\", commit.hexsha, '-r', '--abbrev=40',\u001B[39;00m\n\u001B[1;32m    695\u001B[0m     \u001B[38;5;66;03m#                     '--full-index', '-M', '-p', '--no-color')\u001B[39;00m\n\u001B[1;32m    696\u001B[0m     diff_index \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/OneDrive - Universität Zürich UZH/Uni/Master 3/Fundamentals of Software Systems/Exercise/06/github/fund-data-science-analyze-elasticsearch/venv/lib/python3.8/site-packages/git/diff.py:188\u001B[0m, in \u001B[0;36mDiffable.diff\u001B[0;34m(self, other, paths, create_patch, **kwargs)\u001B[0m\n\u001B[1;32m    185\u001B[0m proc \u001B[38;5;241m=\u001B[39m diff_cmd(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_diff_args(args), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    187\u001B[0m diff_method \u001B[38;5;241m=\u001B[39m Diff\u001B[38;5;241m.\u001B[39m_index_from_patch_format \u001B[38;5;28;01mif\u001B[39;00m create_patch \u001B[38;5;28;01melse\u001B[39;00m Diff\u001B[38;5;241m.\u001B[39m_index_from_raw_format\n\u001B[0;32m--> 188\u001B[0m index \u001B[38;5;241m=\u001B[39m \u001B[43mdiff_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrepo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    190\u001B[0m proc\u001B[38;5;241m.\u001B[39mwait()\n\u001B[1;32m    191\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m index\n",
      "File \u001B[0;32m~/OneDrive - Universität Zürich UZH/Uni/Master 3/Fundamentals of Software Systems/Exercise/06/github/fund-data-science-analyze-elasticsearch/venv/lib/python3.8/site-packages/git/diff.py:541\u001B[0m, in \u001B[0;36mDiff._index_from_patch_format\u001B[0;34m(cls, repo, proc)\u001B[0m\n\u001B[1;32m    538\u001B[0m a_mode \u001B[38;5;241m=\u001B[39m old_mode \u001B[38;5;129;01mor\u001B[39;00m deleted_file_mode \u001B[38;5;129;01mor\u001B[39;00m (a_path \u001B[38;5;129;01mand\u001B[39;00m (b_mode \u001B[38;5;129;01mor\u001B[39;00m new_mode \u001B[38;5;129;01mor\u001B[39;00m new_file_mode))\n\u001B[1;32m    539\u001B[0m b_mode \u001B[38;5;241m=\u001B[39m b_mode \u001B[38;5;129;01mor\u001B[39;00m new_mode \u001B[38;5;129;01mor\u001B[39;00m new_file_mode \u001B[38;5;129;01mor\u001B[39;00m (b_path \u001B[38;5;129;01mand\u001B[39;00m a_mode)\n\u001B[1;32m    540\u001B[0m index\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 541\u001B[0m     \u001B[43mDiff\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    542\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepo\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[43m        \u001B[49m\u001B[43ma_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    544\u001B[0m \u001B[43m        \u001B[49m\u001B[43mb_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m        \u001B[49m\u001B[43ma_blob_id\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ma_blob_id\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdefenc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m        \u001B[49m\u001B[43mb_blob_id\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mb_blob_id\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdefenc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    547\u001B[0m \u001B[43m        \u001B[49m\u001B[43ma_mode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ma_mode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdefenc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    548\u001B[0m \u001B[43m        \u001B[49m\u001B[43mb_mode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mb_mode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdefenc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    549\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnew_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    550\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdeleted_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    551\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcopied_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    552\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrename_from\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    553\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrename_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    554\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    555\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    557\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    558\u001B[0m )\n\u001B[1;32m    560\u001B[0m previous_header \u001B[38;5;241m=\u001B[39m _header\n\u001B[1;32m    561\u001B[0m header \u001B[38;5;241m=\u001B[39m _header\n",
      "File \u001B[0;32m~/OneDrive - Universität Zürich UZH/Uni/Master 3/Fundamentals of Software Systems/Exercise/06/github/fund-data-science-analyze-elasticsearch/venv/lib/python3.8/site-packages/git/diff.py:350\u001B[0m, in \u001B[0;36mDiff.__init__\u001B[0;34m(self, repo, a_rawpath, b_rawpath, a_blob_id, b_blob_id, a_mode, b_mode, new_file, deleted_file, copied_file, raw_rename_from, raw_rename_to, diff, change_type, score)\u001B[0m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;66;03m# Determine whether this diff references a submodule, if it does then\u001B[39;00m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;66;03m# we need to overwrite \"repo\" to the corresponding submodule's repo instead\u001B[39;00m\n\u001B[1;32m    349\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m repo \u001B[38;5;129;01mand\u001B[39;00m a_rawpath:\n\u001B[0;32m--> 350\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m submodule \u001B[38;5;129;01min\u001B[39;00m \u001B[43mrepo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmodules\u001B[49m:\n\u001B[1;32m    351\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m submodule\u001B[38;5;241m.\u001B[39mpath \u001B[38;5;241m==\u001B[39m a_rawpath\u001B[38;5;241m.\u001B[39mdecode(defenc, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreplace\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    352\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m submodule\u001B[38;5;241m.\u001B[39mmodule_exists():\n",
      "File \u001B[0;32m~/OneDrive - Universität Zürich UZH/Uni/Master 3/Fundamentals of Software Systems/Exercise/06/github/fund-data-science-analyze-elasticsearch/venv/lib/python3.8/site-packages/git/repo/base.py:408\u001B[0m, in \u001B[0;36mRepo.submodules\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    403\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msubmodules\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIterableList[Submodule]\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    405\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    406\u001B[0m \u001B[38;5;124;03m    :return: git.IterableList(Submodule, ...) of direct submodules\u001B[39;00m\n\u001B[1;32m    407\u001B[0m \u001B[38;5;124;03m        available from the current head\"\"\"\u001B[39;00m\n\u001B[0;32m--> 408\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSubmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlist_items\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/OneDrive - Universität Zürich UZH/Uni/Master 3/Fundamentals of Software Systems/Exercise/06/github/fund-data-science-analyze-elasticsearch/venv/lib/python3.8/site-packages/git/util.py:1189\u001B[0m, in \u001B[0;36mIterableObj.list_items\u001B[0;34m(cls, repo, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1181\u001B[0m \u001B[38;5;124;03mFind all items of this type - subclasses can specify args and kwargs differently.\u001B[39;00m\n\u001B[1;32m   1182\u001B[0m \u001B[38;5;124;03mIf no args are given, subclasses are obliged to return all items if no additional\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \n\u001B[1;32m   1187\u001B[0m \u001B[38;5;124;03m:return:list(Item,...) list of item instances\"\"\"\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m out_list: IterableList \u001B[38;5;241m=\u001B[39m IterableList(\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_id_attribute_)\n\u001B[0;32m-> 1189\u001B[0m \u001B[43mout_list\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter_items\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrepo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out_list\n",
      "File \u001B[0;32m~/OneDrive - Universität Zürich UZH/Uni/Master 3/Fundamentals of Software Systems/Exercise/06/github/fund-data-science-analyze-elasticsearch/venv/lib/python3.8/site-packages/git/objects/submodule/base.py:1338\u001B[0m, in \u001B[0;36mSubmodule.iter_items\u001B[0;34m(cls, repo, parent_commit, *Args, **kwargs)\u001B[0m\n\u001B[1;32m   1336\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1337\u001B[0m     pc \u001B[38;5;241m=\u001B[39m repo\u001B[38;5;241m.\u001B[39mcommit(parent_commit)  \u001B[38;5;66;03m# parent commit instance\u001B[39;00m\n\u001B[0;32m-> 1338\u001B[0m     parser \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config_parser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrepo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mread_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   1339\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mIOError\u001B[39;00m, BadName):\n\u001B[1;32m   1340\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28miter\u001B[39m([])\n",
      "File \u001B[0;32m~/OneDrive - Universität Zürich UZH/Uni/Master 3/Fundamentals of Software Systems/Exercise/06/github/fund-data-science-analyze-elasticsearch/venv/lib/python3.8/site-packages/git/objects/submodule/base.py:235\u001B[0m, in \u001B[0;36mSubmodule._config_parser\u001B[0;34m(cls, repo, parent_commit, read_only)\u001B[0m\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot write blobs of \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhistorical\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m submodule configurations\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    233\u001B[0m \u001B[38;5;66;03m# END handle writes of historical submodules\u001B[39;00m\n\u001B[0;32m--> 235\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSubmoduleConfigParser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mread_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mread_only\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/OneDrive - Universität Zürich UZH/Uni/Master 3/Fundamentals of Software Systems/Exercise/06/github/fund-data-science-analyze-elasticsearch/venv/lib/python3.8/site-packages/git/objects/submodule/util.py:83\u001B[0m, in \u001B[0;36mSubmoduleConfigParser.__init__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_auto_write \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 83\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mSubmoduleConfigParser\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/OneDrive - Universität Zürich UZH/Uni/Master 3/Fundamentals of Software Systems/Exercise/06/github/fund-data-science-analyze-elasticsearch/venv/lib/python3.8/site-packages/git/config.py:338\u001B[0m, in \u001B[0;36mGitConfigParser.__init__\u001B[0;34m(self, file_or_files, read_only, merge_includes, config_level, repo)\u001B[0m\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    313\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    314\u001B[0m     file_or_files: Union[\u001B[38;5;28;01mNone\u001B[39;00m, PathLike, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBytesIO\u001B[39m\u001B[38;5;124m\"\u001B[39m, Sequence[Union[PathLike, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBytesIO\u001B[39m\u001B[38;5;124m\"\u001B[39m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    318\u001B[0m     repo: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRepo\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    319\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    320\u001B[0m     \u001B[38;5;124;03m\"\"\"Initialize a configuration reader to read the given file_or_files and to\u001B[39;00m\n\u001B[1;32m    321\u001B[0m \u001B[38;5;124;03m    possibly allow changes to it by setting read_only False\u001B[39;00m\n\u001B[1;32m    322\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    336\u001B[0m \n\u001B[1;32m    337\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 338\u001B[0m     \u001B[43mcp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mRawConfigParser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdict_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_OMD\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    339\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dict: Callable[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, _OMD]  \u001B[38;5;66;03m# type: ignore   # mypy/typeshed bug?\u001B[39;00m\n\u001B[1;32m    340\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_defaults: _OMD\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/configparser.py:611\u001B[0m, in \u001B[0;36mRawConfigParser.__init__\u001B[0;34m(self, defaults, dict_type, allow_no_value, delimiters, comment_prefixes, inline_comment_prefixes, strict, empty_lines_in_values, default_section, interpolation, converters)\u001B[0m\n\u001B[1;32m    609\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sections \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dict()\n\u001B[1;32m    610\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_defaults \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dict()\n\u001B[0;32m--> 611\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_converters \u001B[38;5;241m=\u001B[39m \u001B[43mConverterMapping\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    612\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_proxies \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dict()\n\u001B[1;32m    613\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_proxies[default_section] \u001B[38;5;241m=\u001B[39m SectionProxy(\u001B[38;5;28mself\u001B[39m, default_section)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/configparser.py:1320\u001B[0m, in \u001B[0;36mConverterMapping.__init__\u001B[0;34m(self, parser)\u001B[0m\n\u001B[1;32m   1318\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parser \u001B[38;5;241m=\u001B[39m parser\n\u001B[1;32m   1319\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m-> 1320\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m getter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mdir\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parser\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1321\u001B[0m     m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mGETTERCRE\u001B[38;5;241m.\u001B[39mmatch(getter)\n\u001B[1;32m   1322\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m callable(\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parser, getter)):\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from typing import Set\n",
    "\n",
    "repo = Repository(repo_checkout_path, from_tag=from_tag, to_tag=to_tag)\n",
    "\n",
    "files_to_authors : {str, Set[str]} = {}\n",
    "authors_to_files : {str, Set[str]} = {}\n",
    "\n",
    "for commit in repo.traverse_commits():\n",
    "    author_identifier = commit.author.name\n",
    "    authors_to_files.setdefault(author_identifier, set())\n",
    "    for file in commit.modified_files:\n",
    "        if file.new_path is not None:\n",
    "            files_to_authors.setdefault(file.new_path, set())\n",
    "            files_to_authors[file.new_path].add(author_identifier)\n",
    "            authors_to_files[author_identifier].add(file.new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualize Nr of authors per file:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_author_count = {(k, len(authors)) for k, authors in files_to_authors.items()}\n",
    "col_name_author = 'File'\n",
    "col_name_nr_of_authors = 'Nr of authors'\n",
    "df_file_author_count = DataFrame(file_author_count, columns=[col_name_author, col_name_nr_of_authors])\n",
    "df_file_author_count_sorted = df_file_author_count.sort_values(by=[col_name_nr_of_authors], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The 20 files with the most authors:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(df_file_author_count_sorted[:20])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Distribution of author count per file:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist_author_count = px.histogram(df_file_author_count_sorted, x=col_name_nr_of_authors)\n",
    "hist_author_count.show()\n",
    "hist_author_log_count = px.histogram(df_file_author_count_sorted, x=col_name_nr_of_authors, log_y=True)\n",
    "hist_author_log_count.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see in a lot of projects, there are certain files which are touched by a lot of authors, but most files are touched by a single author.\n",
    "The file with the most authors is the pom.xml, where the project configuration is stored.\n",
    "There every developer has to change the file if e.g. a dependency is added, removed or updated.\n",
    "Then follow some tests with 8 or 7 coauthors, and then we are already at a moderate 7, but only between 2 minor releases."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualise Nr of files per author:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "author_file_count = {(k, len(files)) for k, files in authors_to_files.items()}\n",
    "col_name_author = 'Author'\n",
    "col_name_nr_of_files = 'Nr of files'\n",
    "df_author_file_count = DataFrame(author_file_count, columns=[col_name_author, col_name_nr_of_files])\n",
    "df_author_file_count_sorted = df_author_file_count.sort_values(by=[col_name_nr_of_files], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The 20 authors which changed the most files:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(df_author_file_count_sorted[:20])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Distribution of files modified per author:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist_author_count = px.histogram(df_author_file_count_sorted, x=col_name_nr_of_files)\n",
    "hist_author_count.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Most of the people only change a few files, as has been seen in other open source projects.\n",
    "There are some main contributes which changed more than 20 files."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Now, let's look at the following 3 packages in more detail:\n",
    "1. `src/main/java/org/elasticsearch/search`\n",
    "2. `src/main/java/org/elasticsearch/index`\n",
    "3. `src/main/java/org/elasticsearch/action`\n",
    "\n",
    "Create a function that, given the path of a package and a modification type (see class Modification above), returns a dictionary of authors => number, where the number counts the total lines added or removed or added+removed or added-removed (depending on the given Modification parameter), for the given package. To compute the value at the package level, you should aggregate the data per file.\n",
    "\n",
    "Using the function defined above, visualize the author contributions (lines added + lines removed). The visualization should have the author on the x axis, and the total lines on the y axis. Sort the visualization in decreasing amount of contributions, i.e., the main author should be the first.\n",
    "\n",
    "Compare the visualization for the 3 packages and comment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "AuthorChurnDict = Dict[str, Dict[Modification, int]]\n",
    "\n",
    "# noinspection PyShadowingNames\n",
    "def author_churn_of_path(path: str, from_tag: str = from_tag, to_tag: str = to_tag) -> AuthorChurnDict:\n",
    "    modifications: AuthorChurnDict = {}\n",
    "    repo = Repository(path_to_repo=repo_checkout_path, from_tag=from_tag, to_tag=to_tag)\n",
    "    for commit in repo.traverse_commits():\n",
    "        author_identifier = commit.author.name\n",
    "        modifications.setdefault(author_identifier, dict([(mod_type, 0) for mod_type in Modification]))\n",
    "        for file in commit.modified_files:\n",
    "            if file.new_path is None:\n",
    "                continue\n",
    "            if not file.new_path.__contains__(path):\n",
    "                continue\n",
    "            modifications[author_identifier][Modification.ADDED] += file.added_lines\n",
    "            modifications[author_identifier][Modification.REMOVED] += file.deleted_lines\n",
    "            modifications[author_identifier][Modification.TOTAL] += file.added_lines + file.deleted_lines\n",
    "            modifications[author_identifier][Modification.DIFF] += file.added_lines - file.deleted_lines\n",
    "\n",
    "    return modifications\n",
    "\n",
    "display([(k, v) for k, v in author_churn_of_path('src/main/java/org/elasticsearch/search').items()][:20])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "ff9eee63",
   "metadata": {},
   "source": [
    "## Task 2: Knowledge loss\n",
    "\n",
    "We now want to analyze the knowledge loss when the main contributor of the analyzed project would leave. For this we will use the circle packaging layout introduced in the \"Code as a Crime Scene\" book. It should show how much of each file was written by the main contributor of _elasticsearch_ (according to the analysis above using `Modification.TOTAL`) and indicate which areas would be affected most when this contributor leaves the project. This assignment includes the necessary `knowledge_loss.html` file as well as the `d3` folder with the d3 dependencies. Your task is to create the `output.json` file according to the specification below. This file can then be visualized with the files provided.\n",
    "\n",
    "For showing the visualization, once you have the output as `output.json` you should\n",
    "* make sure to have the `knowledge_loss.html` file in the same folder\n",
    "* start a local HTTP server in the same folder (e.g. with python `python3 -m http.server`, serving necessary for d3)\n",
    "* open the served `knowledge_loss.html` and look at the visualization\n",
    "\n",
    "For testing, you can use the provided `output.json` and should see a circle packaging layout with two circles, one big red, and one small white-red.\n",
    "\n",
    "For the package you identify as the worst in terms of knowledge loss, investigate the author contributions using the function defined in the previous exercise and comment how the situation is, e.g. how big the gap between the main author and the second biggest contributor for the selected package is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186eb566",
   "metadata": {},
   "source": [
    "### Output Format for Visualization\n",
    "\n",
    "Example:\n",
    "\n",
    "* `root` is always the root of the tree\n",
    "* `size` should be the total number of lines of contribution\n",
    "* `weight` can be set to the same as `size`\n",
    "* `ownership` should be set to the percentage of contributions from the main author (e.g. 0.98 for 98% if contributions coming from the main author)\n",
    "\n",
    "```\n",
    "{\n",
    "  \"name\": \"root\",\n",
    "  \"children\": [\n",
    "    {\n",
    "      \"name\": \"test\",\n",
    "      \"children\": [\n",
    "        {\n",
    "          \"name\": \"benchmarking\",\n",
    "          \"children\": [\n",
    "            {\n",
    "              \"author_color\": \"red\",\n",
    "              \"size\": \"4005\",\n",
    "              \"name\": \"t6726-patmat-analysis.scala\",\n",
    "              \"weight\": 1.0,\n",
    "              \"ownership\": 0.9,\n",
    "              \"children\": []\n",
    "            },\n",
    "            {\n",
    "              \"author_color\": \"red\",\n",
    "              \"size\": \"55\",\n",
    "              \"name\": \"TreeSetIterator.scala\",\n",
    "              \"weight\": 0.88,\n",
    "              \"ownership\": 0.2,\n",
    "              \"children\": []\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "### JSON Export\n",
    "\n",
    "For exporting the data to JSON you can use the following snippet:\n",
    "\n",
    "```\n",
    "import json\n",
    "\n",
    "with open(\"output.json\", \"w\") as file:\n",
    "    json.dump(tree, file, indent=4)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a1e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fe260b7",
   "metadata": {},
   "source": [
    "## Task 3: Code Churn Analysis\n",
    "\n",
    "The third and last task is to analyze the code churn of the _elasticsearch_ project. For this analysis we look at the code churn, meaning the daily change in the total number of lines of the project. Visualize the code churn over time bucketing the data by day. Remember that you'll need to fill the gaps for days when there are no commits. Chose a filling strategy and justify it.\n",
    "\n",
    "Look at the churn trend over time and identify two outliers. For each of them:\n",
    "- identify if it was caused by a single or multiple commits (since you are bucketing the data by day)\n",
    "- find the hash of the involved commit(s)\n",
    "- find the involved files\n",
    "- look at the actual diff\n",
    "\n",
    "Based on the above, discuss if the outlier is a false positive or should be a reason for concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3fd5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_to_churn = {}\n",
    "\n",
    "for commit in repo.traverse_commits():\n",
    "    date = commit.committer_date.date()\n",
    "    if date in date_to_churn:\n",
    "        date_to_churn[date][\"lines added\"] += commit.insertions\n",
    "        date_to_churn[date][\"lines deleted\"] += commit.deletions\n",
    "        date_to_churn[date][\"hashes\"].append(commit.hash)\n",
    "        date_to_churn[date][\"messages\"].append(commit.msg)\n",
    "    else:\n",
    "        date_to_churn[date] = {\"lines added\":commit.insertions,\n",
    "                               \"lines deleted\":commit.deletions,\n",
    "                               \"hashes\":[commit.hash],\n",
    "                               \"messages\":[commit.msg]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "I choose to add zeros to fill the gaps, because if there are no commits, it means that the amount of lines could not have changed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min_date = min(date_to_churn.keys())\n",
    "max_date = max(date_to_churn.keys())\n",
    "date_list = [entry.date() for entry in pd.date_range(min_date, max_date)]\n",
    "for date in date_list:\n",
    "    if date not in date_to_churn:\n",
    "        date_to_churn[date] = {\"lines added\":0,\n",
    "                               \"lines deleted\":0,\n",
    "                               \"hashes\":[],\n",
    "                               \"messages\":[]}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "from bokeh.layouts import column\n",
    "from bokeh.models import ColumnDataSource, RangeTool\n",
    "from bokeh.models.tools import HoverTool\n",
    "from bokeh.plotting import figure, show\n",
    "import numpy as np\n",
    "\n",
    "items = list(date_to_churn.items())\n",
    "items.sort(key=lambda t: t[0])\n",
    "dates = [datetime.combine(item[0], datetime.min.time()) for item in items]\n",
    "\n",
    "source = ColumnDataSource(data=dict(\n",
    "    date=dates,\n",
    "    added=[item[1]['lines added'] for item in items],\n",
    "    deleted=[item[1]['lines deleted'] for item in items],\n",
    "    hashes=[len(item[1]['hashes']) for item in items],#[item[1]['hashes'] for item in items], TODO\n",
    "    ))\n",
    "\n",
    "p = figure(height=300, width=800, tools=\"xpan\", toolbar_location=None,\n",
    "           x_axis_type=\"datetime\", x_axis_location=\"above\",\n",
    "           x_range=(dates[0], dates[int(len(dates)/4)]))\n",
    "\n",
    "p.line('date', 'added', source=source, color='green', legend_label='added lines')\n",
    "p.line('date', 'deleted', source=source, color='red', legend_label='deleted lines')\n",
    "p.yaxis.axis_label = 'lines of change'\n",
    "p.legend.location = \"top_right\"\n",
    "p.add_tools(HoverTool(tooltips=[\n",
    "            ('date', '@date{%F}'),\n",
    "            ('added', '@added'),\n",
    "            ('deleted', '@deleted'),\n",
    "            ('amount of commits', '@hashes')\n",
    "            ],\n",
    "            formatters={\n",
    "            '@date'        : 'datetime',\n",
    "            #'@hashes'      : 'printf',# use 'datetime' formatter for '@date' field\n",
    "            }))\n",
    "\n",
    "select = figure(height=130, width=800, y_range=p.y_range,\n",
    "                x_axis_type=\"datetime\", y_axis_type=None,\n",
    "                tools=\"\", toolbar_location=None)\n",
    "\n",
    "range_tool = RangeTool(x_range=p.x_range)\n",
    "\n",
    "select.line('date', 'added', source=source, color='green')\n",
    "select.line('date', 'deleted', source=source, color='red')\n",
    "\n",
    "select.add_tools(range_tool)\n",
    "select.toolbar.active_multi = range_tool\n",
    "\n",
    "show(column(p, select))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "def commits_on(date):\n",
    "    hashes = date_to_churn[date]['hashes']\n",
    "\n",
    "    commits = []\n",
    "    for commit in repo.traverse_commits():\n",
    "        if commit.hash in hashes:\n",
    "            commits.append(commit)\n",
    "    return commits\n",
    "\n",
    "def date_overview(date):\n",
    "    print(date)\n",
    "    for commit in commits_on(date):\n",
    "        print_commit_overview(commit)\n",
    "\n",
    "def print_commit_overview(commit):\n",
    "    print(\"\\nhash:\",commit.hash)\n",
    "    for file in commit.modified_files:\n",
    "        print(f\"+{file.added_lines}   \\t-{file.deleted_lines}   \\t{file.new_path if file.new_path else 'del '+file.old_path}\")\n",
    "\n",
    "def print_diff(diff):\n",
    "    for code_line in diff.split('\\n'):\n",
    "        print(code_line)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "analysed_dates_tuples = [(2014, 3, 13), (2014, 2, 26)]\n",
    "analysed_dates = [datetime(*tuple).date() for tuple in analysed_dates_tuples]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-03-13\n",
      "\n",
      "hash: a7230f8d3aa128bd3de112a619e05b191f4df320\n",
      "+1   \t-1   \tsrc/main/java/org/elasticsearch/plugins/PluginsService.java\n",
      "\n",
      "hash: e99c666f8226eebb6daeb7ae1839e28babb38d64\n",
      "+2   \t-2   \tsrc/test/java/org/elasticsearch/discovery/DiscoveryTests.java\n",
      "\n",
      "hash: 822f0873dcb7ee8b678c23c041d6a6966851d830\n",
      "+3   \t-0   \tdocs/community/integrations.asciidoc\n",
      "\n",
      "hash: f7cd6d43aad4a250bd1f3be199c62cfd6b927e91\n",
      "+21   \t-21   \tdocs/reference/search/aggregations.asciidoc\n",
      "\n",
      "hash: c7a3781dcdebe459a6964d669e92a75c4b480587\n",
      "+11   \t-1   \tsrc/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java\n",
      "+112   \t-0   \tsrc/test/java/org/elasticsearch/cluster/ZenUnicastDiscoveryTests.java\n",
      "\n",
      "hash: 406f0836ed9af8b9b81ab4f1f7357ee8148bdee3\n",
      "+6   \t-0   \tsrc/test/java/org/elasticsearch/discovery/DiscoveryTests.java\n",
      "\n",
      "hash: 873ffd3df7687596a20af096fe05b7524fd767ae\n",
      "+1   \t-1   \tsrc/main/java/org/elasticsearch/percolator/PercolatorService.java\n",
      "+18   \t-28   \tsrc/main/java/org/elasticsearch/percolator/QueryCollector.java\n",
      "\n",
      "hash: 8c592101aee9640b42bd9336db33ad7f09d339d2\n",
      "+2   \t-0   \tdocs/reference/search/suggesters.asciidoc\n",
      "+3   \t-0   \tdocs/reference/search/suggesters/completion-suggest.asciidoc\n",
      "+319   \t-0   \tdocs/reference/search/suggesters/context-suggest.asciidoc\n",
      "+128   \t-0   \tsrc/main/java/org/apache/lucene/analysis/PrefixAnalyzer.java\n",
      "+17   \t-7   \tsrc/main/java/org/apache/lucene/search/suggest/analyzing/XAnalyzingSuggester.java\n",
      "+6   \t-5   \tsrc/main/java/org/apache/lucene/search/suggest/analyzing/XFuzzySuggester.java\n",
      "+35   \t-7   \tsrc/main/java/org/elasticsearch/common/geo/GeoHashUtils.java\n",
      "+11   \t-1   \tsrc/main/java/org/elasticsearch/common/geo/GeoPoint.java\n",
      "+59   \t-0   \tsrc/main/java/org/elasticsearch/common/geo/GeohashPathIterator.java\n",
      "+8   \t-0   \tsrc/main/java/org/elasticsearch/common/xcontent/XContentBuilder.java\n",
      "+101   \t-21   \tsrc/main/java/org/elasticsearch/index/mapper/core/CompletionFieldMapper.java\n",
      "+3   \t-2   \tsrc/main/java/org/elasticsearch/index/query/GeohashCellFilter.java\n",
      "+74   \t-0   \tsrc/main/java/org/elasticsearch/search/suggest/SuggestBuilder.java\n",
      "+4   \t-7   \tsrc/main/java/org/elasticsearch/search/suggest/SuggestionSearchContext.java\n",
      "+25   \t-16   \tsrc/main/java/org/elasticsearch/search/suggest/completion/AnalyzingCompletionLookupProvider.java\n",
      "+4   \t-5   \tsrc/main/java/org/elasticsearch/search/suggest/completion/Completion090PostingsFormat.java\n",
      "+52   \t-18   \tsrc/main/java/org/elasticsearch/search/suggest/completion/CompletionSuggestParser.java\n",
      "+20   \t-7   \tsrc/main/java/org/elasticsearch/search/suggest/completion/CompletionSuggestionContext.java\n",
      "+1   \t-1   \tsrc/main/java/org/elasticsearch/search/suggest/completion/CompletionTokenStream.java\n",
      "+341   \t-0   \tsrc/main/java/org/elasticsearch/search/suggest/context/CategoryContextMapping.java\n",
      "+127   \t-0   \tsrc/main/java/org/elasticsearch/search/suggest/context/ContextBuilder.java\n",
      "+316   \t-0   \tsrc/main/java/org/elasticsearch/search/suggest/context/ContextMapping.java\n",
      "+664   \t-0   \tsrc/main/java/org/elasticsearch/search/suggest/context/GeolocationContextMapping.java\n",
      "+21   \t-17   \tsrc/test/java/org/elasticsearch/search/geo/GeoFilterTests.java\n",
      "+640   \t-0   \tsrc/test/java/org/elasticsearch/search/suggest/ContextSuggestSearchTests.java\n",
      "+13   \t-13   \tsrc/test/java/org/elasticsearch/search/suggest/completion/AnalyzingCompletionLookupProviderV1.java\n",
      "+8   \t-7   \tsrc/test/java/org/elasticsearch/search/suggest/completion/CompletionPostingsFormatTest.java\n",
      "+19   \t-0   \tsrc/test/java/org/elasticsearch/test/hamcrest/ElasticsearchGeoAssertions.java\n",
      "\n",
      "hash: 629a82cf5df5f45fb3cb9c68a5508d289687db29\n",
      "+10   \t-12   \tsrc/test/java/org/elasticsearch/broadcast/BroadcastActionsTests.java\n",
      "+3   \t-7   \tsrc/test/java/org/elasticsearch/cluster/ClusterHealthTests.java\n",
      "+1   \t-1   \tsrc/test/java/org/elasticsearch/cluster/ack/AckClusterUpdateSettingsTests.java\n",
      "+4   \t-4   \tsrc/test/java/org/elasticsearch/cluster/ack/AckTests.java\n",
      "+6   \t-3   \tsrc/test/java/org/elasticsearch/cluster/allocation/AwarenessAllocationTests.java\n",
      "+1   \t-1   \tsrc/test/java/org/elasticsearch/cluster/allocation/SimpleAllocationTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/flt/FuzzyLikeThisActionTests.java\n",
      "+16   \t-40   \tsrc/test/java/org/elasticsearch/indices/IndicesOptionsTests.java\n",
      "+13   \t-22   \tsrc/test/java/org/elasticsearch/indices/fielddata/breaker/CircuitBreakerServiceTests.java\n",
      "+0   \t-2   \tsrc/test/java/org/elasticsearch/indices/fielddata/breaker/RandomExceptionCircuitBreakerTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/indices/mapping/ConcurrentDynamicTemplateTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/indices/mapping/SimpleGetFieldMappingsTests.java\n",
      "+6   \t-4   \tsrc/test/java/org/elasticsearch/indices/settings/UpdateNumberOfReplicasTests.java\n",
      "+19   \t-25   \tsrc/test/java/org/elasticsearch/indices/stats/SimpleIndexStatsTests.java\n",
      "+6   \t-0   \tsrc/test/java/org/elasticsearch/indices/template/IndexTemplateFileLoadingTests.java\n",
      "+5   \t-4   \tsrc/test/java/org/elasticsearch/mlt/MoreLikeThisActionTests.java\n",
      "+3   \t-3   \tsrc/test/java/org/elasticsearch/percolator/PercolatorTests.java\n",
      "+6   \t-9   \tsrc/test/java/org/elasticsearch/percolator/RecoveryPercolatorTests.java\n",
      "+18   \t-15   \tsrc/test/java/org/elasticsearch/percolator/TTLPercolatorTests.java\n",
      "+8   \t-5   \tsrc/test/java/org/elasticsearch/recovery/FullRollingRestartTests.java\n",
      "+4   \t-6   \tsrc/test/java/org/elasticsearch/recovery/RecoveryWhileUnderLoadTests.java\n",
      "+10   \t-6   \tsrc/test/java/org/elasticsearch/recovery/SimpleRecoveryTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/StressSearchServiceReaperTest.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/aggregations/CombiTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/aggregations/RandomTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/DateHistogramTests.java\n",
      "+0   \t-7   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/DateRangeTests.java\n",
      "+0   \t-7   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/FilterTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/GeoDistanceTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/GeoHashGridTests.java\n",
      "+0   \t-7   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/GlobalTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/HistogramTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/IPv4RangeTests.java\n",
      "+0   \t-7   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/LongTermsTests.java\n",
      "+0   \t-7   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/MinDocCountTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/MissingTests.java\n",
      "+0   \t-10   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/NaNSortingTests.java\n",
      "+0   \t-7   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/NestedTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/RangeTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/ShardReduceTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/ShardSizeTests.java\n",
      "+0   \t-7   \tsrc/test/java/org/elasticsearch/search/aggregations/bucket/StringTermsTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/aggregations/metrics/AbstractNumericTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/aggregations/metrics/ValueCountTests.java\n",
      "+5   \t-6   \tsrc/test/java/org/elasticsearch/search/basic/SearchWithRandomExceptionsTests.java\n",
      "+12   \t-13   \tsrc/test/java/org/elasticsearch/search/basic/TransportSearchFailuresTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/facet/SimpleFacetsTests.java\n",
      "+1   \t-7   \tsrc/test/java/org/elasticsearch/search/functionscore/RandomScoreFunctionTests.java\n",
      "+7   \t-2   \tsrc/test/java/org/elasticsearch/search/preference/SearchPreferenceTests.java\n",
      "+3   \t-6   \tsrc/test/java/org/elasticsearch/search/rescore/QueryRescorerTests.java\n",
      "+0   \t-5   \tsrc/test/java/org/elasticsearch/search/suggest/CompletionSuggestSearchTests.java\n",
      "+33   \t-57   \tsrc/test/java/org/elasticsearch/search/suggest/ContextSuggestSearchTests.java\n",
      "+3   \t-13   \tsrc/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java\n",
      "+6   \t-4   \tsrc/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreTests.java\n",
      "+19   \t-8   \tsrc/test/java/org/elasticsearch/test/ElasticsearchIntegrationTest.java\n",
      "+14   \t-2   \tsrc/test/java/org/elasticsearch/test/TestCluster.java\n",
      "+20   \t-12   \tsrc/test/java/org/elasticsearch/ttl/SimpleTTLTests.java\n",
      "+3   \t-3   \tsrc/test/java/org/elasticsearch/versioning/ConcurrentDocumentOperationTests.java\n",
      "\n",
      "hash: c57261bd759ddf1a084b537ebb955d94595b661d\n",
      "+8   \t-1   \tsrc/main/java/org/elasticsearch/index/query/FuzzyLikeThisQueryParser.java\n",
      "+1   \t-0   \tsrc/test/java/org/apache/lucene/util/AbstractRandomizedTest.java\n",
      "+36   \t-1   \tsrc/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java\n",
      "\n",
      "hash: abb18484df7700f725c12a2488e6f659711613b6\n",
      "+11   \t-85   \tsrc/main/java/org/elasticsearch/common/util/AbstractHash.java\n",
      "+127   \t-0   \tsrc/main/java/org/elasticsearch/common/util/AbstractPagedHashMap.java\n",
      "+4   \t-1   \tsrc/main/java/org/elasticsearch/common/util/BytesRefHash.java\n",
      "+200   \t-0   \tsrc/main/java/org/elasticsearch/common/util/DoubleObjectPagedHashMap.java\n",
      "+6   \t-9   \tsrc/main/java/org/elasticsearch/common/util/LongHash.java\n",
      "+200   \t-0   \tsrc/main/java/org/elasticsearch/common/util/LongObjectPagedHashMap.java\n",
      "+1   \t-1   \tsrc/main/java/org/elasticsearch/percolator/PercolatorService.java\n",
      "+6   \t-6   \tsrc/main/java/org/elasticsearch/search/aggregations/InternalAggregation.java\n",
      "+5   \t-5   \tsrc/main/java/org/elasticsearch/search/aggregations/InternalAggregations.java\n",
      "+2   \t-2   \tsrc/main/java/org/elasticsearch/search/aggregations/bucket/InternalSingleBucketAggregation.java\n",
      "+17   \t-22   \tsrc/main/java/org/elasticsearch/search/aggregations/bucket/geogrid/InternalGeoHashGrid.java\n",
      "+18   \t-21   \tsrc/main/java/org/elasticsearch/search/aggregations/bucket/histogram/InternalHistogram.java\n",
      "+6   \t-6   \tsrc/main/java/org/elasticsearch/search/aggregations/bucket/range/InternalRange.java\n",
      "+12   \t-17   \tsrc/main/java/org/elasticsearch/search/aggregations/bucket/terms/DoubleTerms.java\n",
      "+8   \t-8   \tsrc/main/java/org/elasticsearch/search/aggregations/bucket/terms/InternalTerms.java\n",
      "+12   \t-17   \tsrc/main/java/org/elasticsearch/search/aggregations/bucket/terms/LongTerms.java\n",
      "+6   \t-3   \tsrc/main/java/org/elasticsearch/search/controller/SearchPhaseController.java\n",
      "+59   \t-0   \tsrc/test/java/org/elasticsearch/common/util/DoubleObjectHashMapTests.java\n",
      "+59   \t-0   \tsrc/test/java/org/elasticsearch/common/util/LongObjectHashMapTests.java\n",
      "\n",
      "hash: ec8bfeae5830f9437fe3db6b46af1f7a96cdfc22\n",
      "+0   \t-5   \tsrc/main/java/org/elasticsearch/search/aggregations/support/AggregationContext.java\n",
      "\n",
      "hash: 90a0cb5ac7f9a34b58567d7f35479209a0d12a40\n",
      "+0   \t-0   \tdocs/reference/images/cardinality_error.png\n",
      "+3   \t-1   \tdocs/reference/search/aggregations/metrics.asciidoc\n",
      "+159   \t-0   \tdocs/reference/search/aggregations/metrics/cardinality-aggregation.asciidoc\n",
      "+156   \t-0   \tsrc/main/java/org/elasticsearch/common/hash/MurmurHash3.java\n",
      "+6   \t-0   \tsrc/main/java/org/elasticsearch/common/util/BigArrays.java\n",
      "+17   \t-0   \tsrc/main/java/org/elasticsearch/common/util/BigByteArray.java\n",
      "+1   \t-0   \tsrc/main/java/org/elasticsearch/common/util/BloomFilter.java\n",
      "+5   \t-0   \tsrc/main/java/org/elasticsearch/common/util/ByteArray.java\n",
      "+23   \t-0   \tsrc/main/java/org/elasticsearch/common/util/UnsafeUtils.java\n",
      "+120   \t-0   \tsrc/main/java/org/elasticsearch/index/fielddata/MurmurHash3Values.java\n",
      "+2   \t-1   \tsrc/main/java/org/elasticsearch/index/mapper/DocumentMapperParser.java\n",
      "+4   \t-0   \tsrc/main/java/org/elasticsearch/index/mapper/MapperBuilders.java\n",
      "+111   \t-0   \tsrc/main/java/org/elasticsearch/index/mapper/core/Murmur3FieldMapper.java\n",
      "+5   \t-0   \tsrc/main/java/org/elasticsearch/search/aggregations/AggregationBuilders.java\n",
      "+2   \t-0   \tsrc/main/java/org/elasticsearch/search/aggregations/AggregationModule.java\n",
      "+2   \t-0   \tsrc/main/java/org/elasticsearch/search/aggregations/TransportAggregationModule.java\n",
      "+31   \t-0   \tsrc/main/java/org/elasticsearch/search/aggregations/metrics/cardinality/Cardinality.java\n",
      "+271   \t-0   \tsrc/main/java/org/elasticsearch/search/aggregations/metrics/cardinality/CardinalityAggregator.java\n",
      "+78   \t-0   \tsrc/main/java/org/elasticsearch/search/aggregations/metrics/cardinality/CardinalityAggregatorFactory.java\n",
      "+57   \t-0   \tsrc/main/java/org/elasticsearch/search/aggregations/metrics/cardinality/CardinalityBuilder.java\n",
      "+134   \t-0   \tsrc/main/java/org/elasticsearch/search/aggregations/metrics/cardinality/CardinalityParser.java\n",
      "+541   \t-0   \tsrc/main/java/org/elasticsearch/search/aggregations/metrics/cardinality/HyperLogLogPlusPlus.java\n",
      "+138   \t-0   \tsrc/main/java/org/elasticsearch/search/aggregations/metrics/cardinality/InternalCardinality.java\n",
      "+162   \t-0   \tsrc/test/java/org/elasticsearch/benchmark/search/aggregations/CardinalityAggregationSearchBenchmark.java\n",
      "+55   \t-0   \tsrc/test/java/org/elasticsearch/common/hashing/MurmurHash3Tests.java\n",
      "+21   \t-0   \tsrc/test/java/org/elasticsearch/common/util/BigArraysTests.java\n",
      "+431   \t-0   \tsrc/test/java/org/elasticsearch/search/aggregations/metrics/CardinalityTests.java\n",
      "+137   \t-0   \tsrc/test/java/org/elasticsearch/search/aggregations/metrics/cardinality/HyperLogLogPlusPlusTests.java\n",
      "+5   \t-0   \tsrc/test/java/org/elasticsearch/test/cache/recycler/MockBigArrays.java\n",
      "\n",
      "hash: a8f645a213e52832d39ddd25beea010e9b7d028d\n",
      "+20   \t-0   \tdev-tools/pmd/custom.xml\n",
      "+69   \t-0   \tpom.xml\n",
      "\n",
      "hash: 8967c4e5615e32bccc78bc2904113858bd8d84e0\n",
      "+5   \t-2   \tsrc/test/java/org/elasticsearch/search/suggest/SuggestSearchTests.java\n",
      "\n",
      "hash: 9124328f6dc87d9a66f919f49d61a9432db4c5dc\n",
      "+6   \t-5   \tsrc/test/java/org/elasticsearch/percolator/ConcurrentPercolatorTests.java\n",
      "\n",
      "hash: 1d2f1503ffa5a326a7b252fc0f928793e9a1d78c\n",
      "+20   \t-8   \tsrc/test/java/org/elasticsearch/search/stats/SearchStatsTests.java\n",
      "\n",
      "hash: e37d61b920f6676dfdb6fed11c9bc757fff6c865\n",
      "+25   \t-5   \tsrc/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java\n"
     ]
    }
   ],
   "source": [
    "date_overview(analysed_dates[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first code churn outlier on 2014-02-26 contains a huge amount of changes, which are non-trivial. So it is indeed a problematic outlier."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-02-26\n",
      "\n",
      "hash: c88aa24bacfbde6e0f65a7f4a45bdab041d96795\n",
      "+2   \t-2   \tsrc/main/java/org/elasticsearch/action/delete/index/IndexDeleteResponse.java\n",
      "+4   \t-15   \tsrc/main/java/org/elasticsearch/action/delete/index/TransportIndexDeleteAction.java\n",
      "+2   \t-17   \tsrc/main/java/org/elasticsearch/action/deletebyquery/TransportIndexDeleteByQueryAction.java\n",
      "+56   \t-8   \tsrc/main/java/org/elasticsearch/action/support/replication/TransportIndexReplicationOperationAction.java\n",
      "+13   \t-5   \tsrc/test/java/org/elasticsearch/deleteByQuery/DeleteByQueryTests.java\n",
      "\n",
      "hash: e751d048c6619f17c96723b6b44d2eed056abf85\n",
      "+9   \t-7   \tTESTING.asciidoc\n",
      "\n",
      "hash: c56ac5158fa925eb25ee8c12d1de217b643835e8\n",
      "+1   \t-1   \tsrc/test/java/org/elasticsearch/node/internal/InternalSettingsPreparerTests.java\n",
      "\n",
      "hash: 1d34626db4a28e8605ef54b8e32ecb47553bc1ae\n",
      "+35   \t-5   \tsrc/main/java/org/elasticsearch/rest/action/deletebyquery/RestDeleteByQueryAction.java\n",
      "\n",
      "hash: f343807f60e83e39e52dc860016b7b1c0ef34663\n",
      "+21   \t-0   \trest-api-spec/test/delete_by_query/10_basic.yaml\n",
      "+2   \t-6   \tsrc/main/java/org/elasticsearch/rest/action/deletebyquery/RestDeleteByQueryAction.java\n",
      "\n",
      "hash: 20594357e9ee65f31375145e4bd18d3c5f2dffbd\n",
      "+0   \t-20   \trest-api-spec/test/delete_by_query/10_basic.yaml\n",
      "\n",
      "hash: 500e37e4a0d7f7f2a506ee90b95ab187021c7397\n",
      "+1   \t-1   \tdocs/reference/query-dsl/queries/multi-match-query.asciidoc\n",
      "\n",
      "hash: a40f504b97222768bd0c462b9234bcdbfe723fa0\n",
      "+83   \t-11   \tsrc/main/java/org/elasticsearch/index/query/SimpleQueryParser.java\n",
      "+10   \t-0   \tsrc/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java\n",
      "+7   \t-5   \tsrc/main/java/org/elasticsearch/index/query/SimpleQueryStringParser.java\n",
      "+19   \t-0   \tsrc/test/java/org/elasticsearch/search/query/SimpleQueryTests.java\n",
      "\n",
      "hash: e0684a112f0266bc57a815cb2494b6bc33b3e70d\n",
      "+2   \t-1   \tsrc/main/java/org/elasticsearch/action/admin/indices/cache/clear/TransportClearIndicesCacheAction.java\n",
      "+21   \t-0   \tsrc/main/java/org/elasticsearch/cache/recycler/PageCacheRecycler.java\n",
      "+9   \t-0   \tsrc/main/java/org/elasticsearch/common/util/AbstractBigArray.java\n",
      "+82   \t-0   \tsrc/main/java/org/elasticsearch/common/util/BigArrays.java\n",
      "+109   \t-0   \tsrc/main/java/org/elasticsearch/common/util/BigFloatArray.java\n",
      "+12   \t-15   \tsrc/main/java/org/elasticsearch/common/util/FloatArray.java\n",
      "+1   \t-12   \tsrc/main/java/org/elasticsearch/index/cache/IndexCache.java\n",
      "+0   \t-2   \tsrc/main/java/org/elasticsearch/index/cache/IndexCacheModule.java\n",
      "+0   \t-46   \tdel src/main/java/org/elasticsearch/index/cache/id/IdCache.java\n",
      "+0   \t-47   \tdel src/main/java/org/elasticsearch/index/cache/id/IdCacheModule.java\n",
      "+3   \t-0   \tsrc/main/java/org/elasticsearch/index/cache/id/IdCacheStats.java\n",
      "+0   \t-35   \tdel src/main/java/org/elasticsearch/index/cache/id/IdReaderCache.java\n",
      "+0   \t-51   \tdel src/main/java/org/elasticsearch/index/cache/id/ShardIdCache.java\n",
      "+0   \t-32   \tdel src/main/java/org/elasticsearch/index/cache/id/ShardIdCacheModule.java\n",
      "+0   \t-353   \tdel src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdCache.java\n",
      "+0   \t-86   \tdel src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdReaderCache.java\n",
      "+0   \t-120   \tdel src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdReaderTypeCache.java\n",
      "+2   \t-1   \tsrc/main/java/org/elasticsearch/index/fielddata/IndexFieldData.java\n",
      "+4   \t-1   \tsrc/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java\n",
      "+9   \t-3   \tsrc/main/java/org/elasticsearch/index/fielddata/ShardFieldData.java\n",
      "+2   \t-1   \tsrc/main/java/org/elasticsearch/index/fielddata/plain/DisabledIndexFieldData.java\n",
      "+2   \t-1   \tsrc/main/java/org/elasticsearch/index/fielddata/plain/DocValuesIndexFieldData.java\n",
      "+2   \t-1   \tsrc/main/java/org/elasticsearch/index/fielddata/plain/DoubleArrayIndexFieldData.java\n",
      "+2   \t-1   \tsrc/main/java/org/elasticsearch/index/fielddata/plain/FSTBytesIndexFieldData.java\n",
      "+2   \t-1   \tsrc/main/java/org/elasticsearch/index/fielddata/plain/FloatArrayIndexFieldData.java\n",
      "+2   \t-1   \tsrc/main/java/org/elasticsearch/index/fielddata/plain/GeoPointBinaryDVIndexFieldData.java\n",
      "+2   \t-1   \tsrc/main/java/org/elasticsearch/index/fielddata/plain/GeoPointCompressedIndexFieldData.java\n",
      "+2   \t-1   \tsrc/main/java/org/elasticsearch/index/fielddata/plain/GeoPointDoubleArrayIndexFieldData.java\n",
      "+2   \t-1   \tsrc/main/java/org/elasticsearch/index/fielddata/plain/PackedArrayIndexFieldData.java\n",
      "+2   \t-1   \tsrc/main/java/org/elasticsearch/index/fielddata/plain/PagedBytesIndexFieldData.java\n",
      "+148   \t-0   \tsrc/main/java/org/elasticsearch/index/fielddata/plain/ParentChildAtomicFieldData.java\n",
      "+84   \t-0   \tsrc/main/java/org/elasticsearch/index/fielddata/plain/ParentChildFilteredTermsEnum.java\n",
      "+197   \t-0   \tsrc/main/java/org/elasticsearch/index/fielddata/plain/ParentChildIndexFieldData.java\n",
      "+327   \t-0   \tsrc/main/java/org/elasticsearch/index/fielddata/plain/ParentChildIntersectTermsEnum.java\n",
      "+6   \t-31   \tsrc/main/java/org/elasticsearch/index/mapper/Uid.java\n",
      "+2   \t-1   \tsrc/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java\n",
      "+7   \t-3   \tsrc/main/java/org/elasticsearch/index/query/HasChildFilterParser.java\n",
      "+12   \t-4   \tsrc/main/java/org/elasticsearch/index/query/HasChildQueryParser.java\n",
      "+7   \t-1   \tsrc/main/java/org/elasticsearch/index/query/HasParentFilterParser.java\n",
      "+8   \t-2   \tsrc/main/java/org/elasticsearch/index/query/HasParentQueryParser.java\n",
      "+13   \t-2   \tsrc/main/java/org/elasticsearch/index/query/TopChildrenQueryParser.java\n",
      "+73   \t-36   \tsrc/main/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQuery.java\n",
      "+211   \t-105   \tsrc/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java\n",
      "+74   \t-35   \tsrc/main/java/org/elasticsearch/index/search/child/ParentConstantScoreQuery.java\n",
      "+0   \t-59   \tdel src/main/java/org/elasticsearch/index/search/child/ParentIdCollector.java\n",
      "+8   \t-15   \tsrc/main/java/org/elasticsearch/index/search/child/ParentIdsFilter.java\n",
      "+117   \t-52   \tsrc/main/java/org/elasticsearch/index/search/child/ParentQuery.java\n",
      "+39   \t-9   \tsrc/main/java/org/elasticsearch/index/search/child/TopChildrenQuery.java\n",
      "+0   \t-3   \tsrc/main/java/org/elasticsearch/index/service/InternalIndexService.java\n",
      "+1   \t-4   \tsrc/main/java/org/elasticsearch/index/shard/service/IndexShard.java\n",
      "+5   \t-12   \tsrc/main/java/org/elasticsearch/index/shard/service/InternalIndexShard.java\n",
      "+0   \t-6   \tsrc/main/java/org/elasticsearch/percolator/PercolateContext.java\n",
      "+8   \t-36   \tsrc/main/java/org/elasticsearch/search/SearchService.java\n",
      "+0   \t-5   \tsrc/main/java/org/elasticsearch/search/internal/DefaultSearchContext.java\n",
      "+0   \t-3   \tsrc/main/java/org/elasticsearch/search/internal/SearchContext.java\n",
      "+0   \t-410   \tdel src/test/java/org/elasticsearch/index/cache/id/SimpleIdCacheTests.java\n",
      "+7   \t-3   \tsrc/test/java/org/elasticsearch/index/fielddata/AbstractFieldDataTests.java\n",
      "+8   \t-3   \tsrc/test/java/org/elasticsearch/index/fielddata/IndexFieldDataServiceTests.java\n",
      "+172   \t-0   \tsrc/test/java/org/elasticsearch/index/fielddata/ParentChildFieldDataTests.java\n",
      "+125   \t-0   \tsrc/test/java/org/elasticsearch/index/fielddata/plain/ParentChildFilteredTermsEnumTests.java\n",
      "+5   \t-7   \tsrc/test/java/org/elasticsearch/index/mapper/UidTests.java\n",
      "+5   \t-0   \tsrc/test/java/org/elasticsearch/index/query/IndexQueryParserFilterCachingTests.java\n",
      "+5   \t-0   \tsrc/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java\n",
      "+5   \t-3   \tsrc/test/java/org/elasticsearch/index/search/FieldDataTermsFilterTests.java\n",
      "+15   \t-10   \tsrc/test/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQueryTests.java\n",
      "+5   \t-1   \tsrc/test/java/org/elasticsearch/index/search/child/ChildrenQueryTests.java\n",
      "+5   \t-2   \tsrc/test/java/org/elasticsearch/index/search/child/ParentConstantScoreQueryTests.java\n",
      "+4   \t-1   \tsrc/test/java/org/elasticsearch/index/search/child/ParentQueryTests.java\n",
      "+5   \t-11   \tsrc/test/java/org/elasticsearch/index/search/child/TestSearchContext.java\n",
      "+25   \t-10   \tsrc/test/java/org/elasticsearch/search/child/SimpleChildQuerySearchTests.java\n",
      "+172   \t-0   \tsrc/test/java/org/elasticsearch/test/index/service/StubIndexService.java\n",
      "\n",
      "hash: 00c4facbf5257e3f9a04d681f4b0156c6952e39e\n",
      "+19   \t-0   \tsrc/test/java/org/elasticsearch/index/fielddata/ParentChildFieldDataTests.java\n",
      "\n",
      "hash: 455fdedc905be2ce220e42397979c65558fa095a\n",
      "+1   \t-3   \tsrc/main/java/org/elasticsearch/common/util/AbstractHash.java\n",
      "+1   \t-2   \tsrc/main/java/org/elasticsearch/common/util/BytesRefHash.java\n",
      "+1   \t-3   \tsrc/main/java/org/elasticsearch/common/util/LongHash.java\n",
      "+1   \t-1   \tsrc/main/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQuery.java\n",
      "+1   \t-1   \tsrc/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java\n",
      "+1   \t-1   \tsrc/main/java/org/elasticsearch/index/search/child/ParentConstantScoreQuery.java\n",
      "+1   \t-1   \tsrc/main/java/org/elasticsearch/index/search/child/ParentIdsFilter.java\n",
      "+1   \t-1   \tsrc/main/java/org/elasticsearch/index/search/child/ParentQuery.java\n",
      "+1   \t-1   \tsrc/main/java/org/elasticsearch/search/aggregations/bucket/geogrid/GeoHashGridAggregator.java\n",
      "+1   \t-1   \tsrc/main/java/org/elasticsearch/search/aggregations/bucket/histogram/HistogramAggregator.java\n",
      "+1   \t-1   \tsrc/main/java/org/elasticsearch/search/aggregations/bucket/terms/DoubleTermsAggregator.java\n",
      "+1   \t-1   \tsrc/main/java/org/elasticsearch/search/aggregations/bucket/terms/LongTermsAggregator.java\n",
      "+1   \t-1   \tsrc/main/java/org/elasticsearch/search/aggregations/bucket/terms/StringTermsAggregator.java\n",
      "+1   \t-2   \tsrc/test/java/org/elasticsearch/common/util/BytesRefHashTests.java\n",
      "+2   \t-1   \tsrc/test/java/org/elasticsearch/common/util/LongHashTests.java\n",
      "\n",
      "hash: 8d7d3e1d6f07e6f2c7c12d9250753393a49c4e34\n",
      "+3   \t-3   \tdocs/reference/query-dsl/filters/has-child-filter.asciidoc\n",
      "+3   \t-3   \tdocs/reference/query-dsl/filters/has-parent-filter.asciidoc\n",
      "+3   \t-3   \tdocs/reference/query-dsl/queries/has-child-query.asciidoc\n",
      "+3   \t-3   \tdocs/reference/query-dsl/queries/has-parent-query.asciidoc\n",
      "+3   \t-3   \tdocs/reference/query-dsl/queries/top-children-query.asciidoc\n",
      "\n",
      "hash: 77f37a9123cfde448bb9a4c19472182c844589cf\n",
      "+1   \t-7   \tpom.xml\n",
      "+0   \t-2096   \tdel src/main/java/org/apache/lucene/analysis/miscellaneous/XASCIIFoldingFilter.java\n",
      "+0   \t-627   \tdel src/main/java/org/apache/lucene/queryparser/XSimpleQueryParser.java\n",
      "+0   \t-326   \tdel src/main/java/org/apache/lucene/search/XReferenceManager.java\n",
      "+0   \t-177   \tdel src/main/java/org/apache/lucene/search/XSearcherManager.java\n",
      "+35   \t-3   \tsrc/main/java/org/apache/lucene/search/suggest/analyzing/XAnalyzingSuggester.java\n",
      "+1   \t-1   \tsrc/main/java/org/elasticsearch/Version.java\n",
      "+4   \t-1   \tsrc/main/java/org/elasticsearch/common/lucene/Lucene.java\n",
      "+4   \t-13   \tsrc/main/java/org/elasticsearch/env/NodeEnvironment.java\n",
      "+2   \t-2   \tsrc/main/java/org/elasticsearch/index/analysis/ASCIIFoldingTokenFilterFactory.java\n",
      "+3   \t-3   \tsrc/main/java/org/elasticsearch/index/analysis/ShingleTokenFilterFactory.java\n",
      "+1   \t-14   \tsrc/main/java/org/elasticsearch/index/engine/SegmentsStats.java\n",
      "+10   \t-21   \tsrc/main/java/org/elasticsearch/index/engine/internal/InternalEngine.java\n",
      "+20   \t-11   \tsrc/main/java/org/elasticsearch/index/fielddata/fieldcomparator/BytesRefOrdValComparator.java\n",
      "+11   \t-5   \tsrc/main/java/org/elasticsearch/index/fielddata/fieldcomparator/BytesRefValComparator.java\n",
      "+3   \t-3   \tsrc/main/java/org/elasticsearch/index/fielddata/fieldcomparator/DoubleScriptDataComparator.java\n",
      "+2   \t-4   \tsrc/main/java/org/elasticsearch/index/fielddata/fieldcomparator/DoubleValuesComparatorBase.java\n",
      "+3   \t-3   \tsrc/main/java/org/elasticsearch/index/fielddata/fieldcomparator/GeoDistanceComparator.java\n",
      "+2   \t-4   \tsrc/main/java/org/elasticsearch/index/fielddata/fieldcomparator/LongValuesComparatorBase.java\n",
      "+6   \t-0   \tsrc/main/java/org/elasticsearch/index/fielddata/fieldcomparator/NumberComparatorBase.java\n",
      "+10   \t-3   \tsrc/main/java/org/elasticsearch/index/fielddata/fieldcomparator/StringScriptDataComparator.java\n",
      "+1   \t-1   \tsrc/main/java/org/elasticsearch/index/gateway/fs/FsIndexShardGateway.java\n",
      "+1   \t-9   \tsrc/main/java/org/elasticsearch/index/query/SimpleQueryParser.java\n",
      "+11   \t-12   \tsrc/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java\n",
      "+0   \t-1   \tsrc/main/java/org/elasticsearch/index/query/SimpleQueryStringParser.java\n",
      "+8   \t-2   \tsrc/main/java/org/elasticsearch/index/search/nested/NestedFieldComparatorSource.java\n",
      "+12   \t-0   \tsrc/test/java/org/elasticsearch/index/analysis/ShingleTokenFilterFactoryTests.java\n",
      "+7   \t-0   \tsrc/test/java/org/elasticsearch/index/analysis/shingle_analysis.json\n",
      "+13   \t-17   \tsrc/test/java/org/elasticsearch/indices/warmer/SimpleIndicesWarmerTests.java\n",
      "+6   \t-3   \tsrc/test/java/org/elasticsearch/test/engine/MockInternalEngine.java\n",
      "\n",
      "hash: 3ab8b2d0ed6e056413d9d35a367c91c556b5bb76\n",
      "+4   \t-0   \tdocs/reference/analysis/tokenfilters/shingle-tokenfilter.asciidoc\n",
      "+18   \t-14   \tsrc/main/java/org/elasticsearch/index/analysis/ShingleTokenFilterFactory.java\n",
      "+1   \t-2   \tsrc/test/java/org/elasticsearch/index/analysis/ShingleTokenFilterFactoryTests.java\n",
      "\n",
      "hash: 5dd155510195c8a7df7f72ed48ea5ee4c7c5049f\n",
      "+6   \t-4   \tsrc/main/java/org/elasticsearch/common/geo/GeoDistance.java\n",
      "+9   \t-0   \tsrc/main/java/org/elasticsearch/common/geo/GeoUtils.java\n",
      "+0   \t-6   \tsrc/test/java/org/apache/lucene/util/SloppyMathTests.java\n",
      "\n",
      "hash: 2bc894034805e0df5c3d6868fbe884c65989ad4f\n",
      "+6   \t-0   \tdev-tools/client_tests_urls.prop\n"
     ]
    }
   ],
   "source": [
    "date_overview(analysed_dates[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The second code churn outlier on 2014-02-26 also contains a huge amount of changes, which are non-trivial. So it is indeed a problematic outlier."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
